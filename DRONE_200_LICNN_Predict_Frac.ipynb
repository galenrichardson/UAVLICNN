{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Citation for the below code\n",
    "'''\n",
    "Title: CCMEO LiCNN Prediction\n",
    "Authors: Galen Richardson, Krishan Rajaratnam, Julie Lovitt\n",
    "Date: 07-14-2021\n",
    "Version: 1.1\n",
    "https://www.nrcan.gc.ca/science-and-data/research-centres-and-labs/canada-centre-remote-sensing/21749\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "loved-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np \n",
    "import os, shutil, time, csv,math\n",
    "import tifffile as tif\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image as kimg\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input,UpSampling2D, Conv2D \n",
    "from tensorflow.keras.layers import concatenate,Dropout, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from PIL import Image,ImageOps\n",
    "import skimage.color as color\n",
    "import cv2\n",
    "import tifffile as TIF\n",
    "\n",
    "#for dislaying results\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "plt.rcParams['figure.dpi'] = 150 \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "atomic-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up project dir\n",
    "project_dir = Path(\"\").resolve().parents[0]\n",
    "\n",
    "Model_Weights = str(project_dir / 'lichen_DRONE_333_VTAUG.h5')\n",
    "\n",
    "input_image = str(project_dir / 'data/raw/d15_cor.tif')\n",
    "drone_tiles = str(project_dir / 'data/raw/Drone_Tiles')\n",
    "strips_folder= str(project_dir / 'data/raw/Drone_Strip')\n",
    "drone_resize_img = str(project_dir / 'data/raw/d15_Drone_resize_rbg.png')\n",
    "\n",
    "LiCNN_tiles = str(project_dir / 'data/raw/LICNN_Tiles')\n",
    "LiCNN_Strips= str(project_dir / 'data/raw/LICNN_Strip')\n",
    "LiCNN_img = str(project_dir / 'data/raw/d15_LICNN_img_frac_333_VTaug.png')\n",
    "\n",
    "Transpose_img =  str(project_dir / 'data/raw/d15_overlay_LICNN_frac_333_Vtaug.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dynamic-cycling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22894, 25652, 3)\n",
      "lol this needs resizing\n",
      "Drone tiles created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def breakup(input_image,drone_tiles):\n",
    "    ts=240\n",
    "    if os.path.exists(drone_tiles):\n",
    "        shutil.rmtree(drone_tiles)\n",
    "        os.makedirs(drone_tiles)\n",
    "    else:\n",
    "        os.makedirs(drone_tiles)\n",
    "    img=tif.imread(input_image)\n",
    "    img_shape = img.shape\n",
    "    print (img_shape)\n",
    "    x=math.ceil(img.shape[0]/ts)*ts-img.shape[0]\n",
    "    y=math.ceil(img.shape[1]/ts)*ts-img.shape[1]\n",
    "    if img.shape[0]/ts and img.shape[1]/ts != int():\n",
    "        print ('lol this needs resizing')\n",
    "        color = [0, 0, 0]\n",
    "        img = cv2.copyMakeBorder(img, 0, x, 0, y, cv2.BORDER_CONSTANT, value=color)\n",
    "        img_shape = img.shape\n",
    "    tile_size = (ts, ts)\n",
    "    offset = (ts,ts)\n",
    "    global tile_list\n",
    "    tile_list=[]\n",
    "    folder_path=drone_tiles\n",
    "    for i in range(int(math.ceil(img_shape[0]/(offset[1] * 1.0)))):\n",
    "        for j in range(int(math.ceil(img_shape[1]/(offset[0] * 1.0)))):\n",
    "            cropped_img = img[offset[1]*i:min(offset[1]*i+tile_size[1], img_shape[0]), offset[0]*j:min(offset[0]*j+tile_size[0], img_shape[1])]\n",
    "        # Debugging the tiles\n",
    "            im_rgb = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB)\n",
    "            tile=str(i) + ',' + str(j)\n",
    "            img_path=folder_path + tile + \".png\"\n",
    "            tile_list.append(tile)\n",
    "            cv2.imwrite(img_path, im_rgb)\n",
    "    print ('Drone tiles created')\n",
    "breakup(input_image,drone_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "meaning-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def marry(tiles,strips,resize_img,modes):\n",
    "    max_t=tile_list[-1]\n",
    "    max_t=list(max_t.split(\",\")) \n",
    "    strip_list = []\n",
    "    for i in range (int(max_t[0])+1):\n",
    "        ilist=[]\n",
    "        for j in range (int(max_t[1])+1):\n",
    "            string=tiles+str(i)+','+str(j)+'.png'\n",
    "            ilist.append(string)\n",
    "            if int(j)==int(max_t[1]):\n",
    "                imgs= [Image.open(h).convert(\"RGB\")  for h in ilist ]\n",
    "                imgs_comb = np.hstack( (np.asarray( h) for h in imgs ) )\n",
    "                im_rgb = cv2.cvtColor(imgs_comb, cv2.COLOR_BGR2RGB)\n",
    "                strip_list.append(strips +str(i)+'.png')\n",
    "                cv2.imwrite((strips +str(i)+'.png'), im_rgb)\n",
    "    print(\"creation of strips completed\")\n",
    "    imgs=[Image.open(i) for i in strip_list ]\n",
    "    imgs_comb = np.vstack(np.asarray( v) for v in imgs )\n",
    "    if modes==True:\n",
    "        print('Applying median filter')\n",
    "        imgs_comb = cv2.medianBlur(imgs_comb, 21) # Add median filter to image\n",
    "        out_pil=Image.fromarray(imgs_comb)\n",
    "        pixels = out_pil.load()\n",
    "        for x in range(out_pil.size[0]): # for every pixel:\n",
    "            for j in range(out_pil.size[1]):\n",
    "                y=pixels[x,j]\n",
    "                if y==(25,25,200): \n",
    "                    pixels[x,j]=(255,25,255)\n",
    "        imgs_comb=np.array(out_pil)\n",
    "    im_rgb = cv2.cvtColor(imgs_comb, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(resize_img, im_rgb)\n",
    "    print(\"resized drone image create\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "buried-enough",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gamr0\\anaconda3\\envs\\RTX_LICNN\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creation of strips completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gamr0\\anaconda3\\envs\\RTX_LICNN\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resized drone image create\n"
     ]
    }
   ],
   "source": [
    "marry(drone_tiles,strips_folder,drone_resize_img,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "friendly-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_make_out(drone_tiles, LiCNN_tiles, symlinks=False, ignore=None):\n",
    "    pred_list =[]\n",
    "    if os.path.exists(LiCNN_tiles):\n",
    "        shutil.rmtree(LiCNN_tiles)\n",
    "        os.makedirs(LiCNN_tiles)\n",
    "    else:\n",
    "        os.makedirs(LiCNN_tiles)\n",
    "    for item in os.listdir(drone_tiles):\n",
    "        s = os.path.join(drone_tiles, item)\n",
    "        d = os.path.join(LiCNN_tiles, item)\n",
    "        if os.path.isdir(s):\n",
    "            shutil.copytree(s, d, symlinks, ignore)\n",
    "        else:\n",
    "            shutil.copy2(s, d)\n",
    "    for path,subdir,files in os.walk(LiCNN_tiles):\n",
    "        for file in files:\n",
    "            pred_list.append(path+'\\\\'+file)\n",
    "    print(\"Dir Copied and pred list created\")\n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "gothic-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the loss function\n",
    "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    dice = K.mean((2. * intersection + smooth)/(union + smooth), axis=0)\n",
    "    return dice\n",
    "def ModifiedDiceLoss(y_true, y_pred, smooth=1e-6, modification = 1):\n",
    "    cce = tf.losses.CategoricalCrossentropy()\n",
    "    return 1 - dice_coef(y_true, y_pred) + modification * cce(y_true, y_pred)\n",
    "def iou_coef(y_true, y_pred, smooth=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "def U_model():\n",
    "    OUTPUT_CHANNELS = 3\n",
    "    in1 = Input(shape=(None, None, 3 ))\n",
    "    #changing all dropouts from .2 to .3\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(in1)\n",
    "    conv1 = Dropout(0.3)(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool1)\n",
    "    conv2 = Dropout(0.3)(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool2)\n",
    "    conv3 = Dropout(0.3)(conv3)\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv3)\n",
    "    conv4 = Dropout(0.3)(conv4)\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv4)\n",
    "    conv4 = Dropout(0.3)(conv4)\n",
    "    \n",
    "    up2 = concatenate([UpSampling2D((2, 2))(conv4), conv2], axis=-1)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up2)\n",
    "    conv6 = Dropout(0.3)(conv6)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n",
    "\n",
    "    up2 = concatenate([UpSampling2D((2, 2))(conv6), conv1], axis=-1)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up2)\n",
    "    conv7 = Dropout(0.3)(conv7)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv7)\n",
    "    segmentation = Conv2D(3, (1, 1), activation='sigmoid', name='seg')(conv7)\n",
    "    \n",
    "    #defining inputs and outputs of model\n",
    "    model = Model(inputs=[in1], outputs=[segmentation])\n",
    "    #loss function needs to be SparseCategoricalCrossentropy\n",
    "    '''Loss function Issues'''\n",
    "    losses = {'seg': ModifiedDiceLoss}\n",
    "    #losses = {'seg': DiceLoss}\n",
    "    #tf.losses.CategoricalCrossentropy()\n",
    "    metrics = {'seg': ['acc']}\n",
    "    #compile the model to create it\n",
    "    model.compile(optimizer=\"adam\", loss = losses, metrics=['acc', dice_coef, iou_coef])\n",
    "    \n",
    "    #look into best loss function for this\n",
    "\n",
    "    return model\n",
    "model = U_model()\n",
    "model.load_weights(Model_Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rocky-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_predict(in_image):\n",
    "    im=Image.open(in_image)\n",
    "    im=np.array(im)\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    arg = tf.convert_to_tensor(im, dtype=tf.uint8)\n",
    "    arg = tf.cast(arg, tf.float32) / 255.0\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        pred_mask = model.predict(arg)\n",
    "        pred_mask = tf.argmax(pred_mask, axis=-1)#which ever class the output data is most similar to, it gets assigned that\n",
    "        pred_mask = tf.expand_dims(pred_mask, axis=-1)\n",
    "    pred_mask= np.squeeze(pred_mask)\n",
    "    pred_mask=pred_mask.astype(int)\n",
    "    return pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ancient-stevens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir Copied and pred list created\n",
      "Predict Runtime: 759.17\n"
     ]
    }
   ],
   "source": [
    "def run_pred_make_out(drone_tiles, LiCNN_tiles):\n",
    "    start1 = time.time()\n",
    "    pred_list=copy_make_out(drone_tiles, LiCNN_tiles)\n",
    "    for i in pred_list:\n",
    "        open_i=cv2.imread(i)\n",
    "        if np.max(open_i)<1:\n",
    "            continue\n",
    "        else:\n",
    "            out=tf_predict(i)\n",
    "            out_pil=Image.fromarray(out)\n",
    "            out_pil = out_pil.convert('RGB')\n",
    "            pixels = out_pil.load()\n",
    "            for x in range(out_pil.size[0]): # for every pixel:\n",
    "                for j in range(out_pil.size[1]):\n",
    "                    y=pixels[x,j]\n",
    "                        #pixels[x,j]=(200,200,25)cyan\n",
    "                        #pixels[x,j]=(255,25,255)purple\n",
    "                    if y==(2,2,2): \n",
    "                        pixels[x,j]=(25,25,255)#red\n",
    "                    if y==(1,1,1): \n",
    "                        pixels[x,j]=(255,25,25)#blue\n",
    "                    #if y==(0,0,0): \n",
    "                        #pixels[x,j]=(25,255,25)#purple\n",
    "            out_pil = out_pil.convert('RGB')\n",
    "            out_fin=np.array(out_pil)\n",
    "            cv2.imwrite(i[:-3]+'png',out_fin)\n",
    "    end1 = time.time()\n",
    "    print(\"Predict Runtime: \"+str(\"%.2f\"%(end1 - start1)))\n",
    "run_pred_make_out(drone_tiles, LiCNN_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "structural-roulette",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gamr0\\anaconda3\\envs\\RTX_LICNN\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creation of strips completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gamr0\\anaconda3\\envs\\RTX_LICNN\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resized drone image create\n"
     ]
    }
   ],
   "source": [
    "#create LICNN cover image\n",
    "marry(LiCNN_tiles,LiCNN_Strips,LiCNN_img,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "latter-anatomy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images read, now starting the merge\n",
      "Image Complete! Runtime: 81.73\n"
     ]
    }
   ],
   "source": [
    "def Transpose_L_cover_on_drone(drone_resize_img,LiCNN_img,Transpose_img):\n",
    "    start1 = time.time()\n",
    "    Trans_pil = cv2.imread(LiCNN_img)\n",
    "    OG_IMG= cv2.imread(drone_resize_img)\n",
    "    print(\"Images read, now starting the merge\")\n",
    "    background = np.array(OG_IMG).astype(np.uint8)\n",
    "    overlay = np.array(Trans_pil).astype(np.uint8)\n",
    "\n",
    "    ignore_color=[0,0,0]\n",
    "    ignore_color = np.asarray(ignore_color)\n",
    "    mask = ~(overlay==ignore_color).all(-1)\n",
    "    out = background.copy()\n",
    "    out[mask] = background[mask] * 0.35 + overlay[mask] * 0.65\n",
    "\n",
    "    cv2.imwrite(Transpose_img,out)\n",
    "    end1 = time.time()\n",
    "    print(\"Image Complete! Runtime: \"+str(\"%.2f\"%(end1 - start1)))\n",
    "Transpose_L_cover_on_drone(drone_resize_img,LiCNN_img,Transpose_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
